\subsection{Systemarchitektur}

Das Materialflusssystem auf den \textsc{Mica}z-Modulen ist in einer Schichtenarchitektur aufgebaut. Diese ist an den Aufbau von AUTOSAR \cite{AUTOSAR:2014:Online} angelehnt. Abbildungen \ref{fig:architecture_ramp} und \ref{fig:architecture_vb} zeigen den Aufbau des Systems auf den Rampen beziehungsweise Volksbots.

\begin{figure}[h!]
 \centering
		\includegraphics[width=1\textwidth]{flow/Architektur_Rampe.png}
	\caption{Architektur der Rampe \cite{Stasch:Hahn}}
	\label{fig:architecture_ramp}
\end{figure}

\begin{figure}[h!]
 \centering
		\includegraphics[width=1\textwidth]{flow/Architektur_VB.png}
	\caption{Architektur der Volksbots aus Sicht des Materialfluss \cite{Stasch:Hahn}}
	\label{fig:architecture_vb}
\end{figure}

Ganz unten in der Hierarchie befindet sich die eigentliche \textsc{Mica}z Hardware (Hardware Level) mit allen Peripherie-Komponenten. Diese wird vom den darüber liegenden Background Level angesteuert. Im Backgrund Level befinden sich im je nach Modul hardwareabhängige Treiber für drahtlose und serielle Kommunikation, Lichtschranken, Bolzen und einen externen Flash-Speicher. Diese agieren meist auf Pin-Ebene, steuern also die einzelnen GPIOs des Mikrocontrollers. Eine Besonderheit stellt hier der Radio-Driver dar, der nicht direkt auf die Hardware, sondern auf den Kommunikationsstack des Echtzeitbetriebssystems Contiki zugreift.

Darüber finden sich Interfaces, die die Funktionen der Treiber aufbereiten und in Funktionen gliedern, die es den oberen Schichten erlauben, ohne großen Aufwand und Kenntnis der Implementierungsdetails (konkreter Ein- beziehungsweise Ausgangs-Pin, Timing, usw.) auf die Hardware zuzugreifen. Neben den Treibern und Interfaces befindet sich im Background Level auch das Echtzeitbetriebssystem Contiki OS. Dieses beinhaltet unter anderem einen Scheduler, eine Prozessverwaltung und den Kommunikationsstack \textit{Rime} (siehe \autoref{sec:rime}). 

Schließlich folgt auf der höchsten Hierarchieebene das Agent Level. Hier befindet sich zunächst das AgentRTE, eine Laufzeitumgebung für Agenten. Dieses ist weitgehend hardwareunabhängig. Lediglich bei der Prozessverwaltung gibt es noch Unterschiede die in \autoref{sec:AgentRTE} noch näher betrachtet werden.
Aufgaben des AgentRTE sind vor allem die Verwaltung aller Agenten auf der Plattform und deren Scheduling, sowie der Austausch von Nachrichten untereinander.

Das letzte Glied in der Kette bilden letztendlich die Agenten. Sie werden vom AgentenRTE verwaltet und sind grundsätzlich hardwareunabhängig. Die Agenten bilden die echte Betriebslogik des Systems ab und kommunizieren dafür untereinander mit Nachrichten. Auf jedem Modul gibt es einen Platform-, einen Order- und einen Routing-Agenten. Dazu können auf den Volksbots ein und auf den Rampen bis zu vier Paket-Agenten registriert sein.

In den folgenden Abschnitten wird nun die Implementierung des Materialflusssystems anhand dieser Architektur erläutert, beginnend beim Echtzeitbetriebssystem Contiki, über die Treiber und Interfaces hin zum AgentenRTE und schließlich den Agenten.

\subsubsection{Contiki}
Contiki ist ein quelloffenes Echtzeitbetriebssystem (RTOS: Real Time Operating System), das in dieser Projektgruppe auf den \textsc{Mica}z-Modulen eingesetzt wird. Es ist speziell für die Anforderungen des Internet of Things und von Wireless Sensor Networks zugeschnitten und bietet einen einfachen ereignisgesteuerten Betriebssystemkern mit sogenannten Protothreads (Threads, die sich einen gemeinsamen Stack teilen und daher schnell gewechselt werden können), optionalem präemptives Multithreading, Interprozess-Kommunikation via Message-Passing mit Events, eine dynamische Prozessstruktur mit Unterstützung für das Laden und Beenden von Prozessen und einen nativen Kommunikationsstack für die drahtlose Kommunikation gemäß dem IEEE-Standard \textit{802.15.4}.
 
\paragraph{Build-Vorgang}\mbox{}\\
Ein laufendes Contiki System besteht aus dem Kernel, Bibliotheken, Prozessen und dem Programm-Lader, mit dem Anwendungen zur Laufzeit aus dem Speicher oder \"uber ein Funkmodul geladen werden k\"onnen.
Die unten stehende Abbildung zeigt die Aufteilung des Betriebssystems in zwei Teile. 
\begin{figure}[h!]
	\centering
		\includegraphics[width=0.9\textwidth]{Systemarchitektur_Contiki.png}
	\caption{Komponenten von Contiki \cite{Dunkels:Groenvall:Voigt:2014:Online}}
	\label{Systemarchitektur von Contiki}
\end{figure}
Der Core ist ein Basissystem und besteht aus dem Kernel, Bibliotheken, Ger\"{a}tetreibern und dem Programm-Lader. 
Im allgemeinen sind \"Anderungen am Core nicht vorgesehen und nur unter Verwendung eines speziellen Bootloaders m\"oglich. 
Die konkrete Aufteilung des Systems in Core und ladbare Programme wird beim Kompilieren des Systems entschieden und h\"angt 
von der Hardware-Plattform ab \cite[vgl.][S. 7]{Walter:2010}. Ger\"atetreiber werden als Bibliotheken implementiert. 

\paragraph{Prozesse}\mbox{}\\
Prozesse in Contiki implementieren ein Konzept namens Protothreads. Dies erlaubt es Prozessen, ohne den Overhead und die langen 
Prozesswechselzeiten von normalen Threads auszukommen. Gleichzeitig k\"onnen trotzdem andere Prozesse ausgef\"uhrt werden, falls ein Prozess auf ein Event (Timer, Nachricht von anderem Prozess...) warten muss.
F\"ur die Entwicklung mit Prozessen ist wichtig, dass nicht-statische Variablen nicht zwischen zwei Aufrufen erhalten bleiben.
Der relevante Status eines Prozesses sollte daher mithilfe von statischen Variablen abgelegt werden (siehe Variable i im folgenden Beispiel)

\begin{figure}[h!]
	\centering
		\includegraphics[width=0.9\textwidth]{Beispielprozess.png}
	\label{Beispielprozess}
\end{figure}
In Zeile 1 wird der Prozess initialisiert und in Zeile 2 automatisch beim Boot von Contiki gestartet. Zeile 4 beinhaltet die
Deklaration. So k\"onnen andere Prozesse diesem Prozess Events (mit oder ohne Daten) schicken, auf die unser Beispielprozess 
mit ev und data zugreifen kann. Zeile 6 kennzeichnet den Beginn der tats\"achlichen Ablauflogik. Code \"uber dieser Zeile wird 
bei jedem Prozessaufruf ausgef\"uhrt, dies wird jedoch in den meisten F\"allen nicht ben\"otigt. Zeile 13 schlie{\ss}lich beendet
den Prozess und entfernt ihn aus der Prozess-Liste des Kernels. In diesem Beispiel wird die Zeile jedoch nie erreicht, sodass der Prozess immer wieder aufgerufen wird, bis er von einem anderen Prozess beendet wird.
Wichtige Funktionen in Prozessen:
\begin{itemize}
\item PROCESS\_WAIT\_EVENT() - Wartet auf ein beliebiges Event, bevor die Ausf\"{u}hrung fortgesetzt wird.
\item PROCESS\_WAIT\_EVENT\_UNTIL(condition) - Wartet auf ein beliebiges Event, setzt die Ausf\"{u}hrung aber nur fort, wenn die Bedingung erf\"{u}llt ist.
\item PROCESS\_WAIT\_UNTIL() - Wartet, bis die Bedingung erf\"ullt ist. Muss den Prozess nicht zwangsl\"{a}ufig anhalten.
\end{itemize}
Prozesse k\"onnen \"uber Events (siehe Events) oder Polling-Anfragen kommunizieren.  Polls sind Events mit hoher Priorit\"at und 
k\"onnen genutzt werden, um den angerufenen Prozess so schnell wie m\"oglich auszuf\"uhren. Sie
sind besonders bei der Abarbeitung von Hardware-Interrupts wichtig, da Interrupts-Handler keine Events, sondern nur
Polling-Anfragen absetzten d\"urfen \cite[vgl.][S. 7]{Walter:2010}.

\paragraph{Prozesskommunikation}\mbox{}\\
In Contiki kommunizieren Prozesse \"uber Events. Auch der Kernel versendet Events, um Prozesse \"uber ihren Status 
(Init, Continue, Exit) oder \"uber abgelaufene Timer zu Informieren. Zur Identifikation stehen dabei Event IDs zur 
Verf\"ugung. Die Event IDs 0-127 k\"onnen vom Benutzer frei vergeben werden, w\"ahrend die Prozess IDs ab 128 vom 
System genutzt werden. Grunds\"atzlich unterscheidet Contiki zwischen synchronen und asynchronen Events. 
\begin{itemize}
\item \textbf{Asynchrone Events} sind eine Form der Deferred Procedure Call: asynchrone Events werden vom Kernel in einer 
Warteschlange gespeichert. Die Scheduling-Funktion des Kernels l\"auft nach Systemstart in einer Endlosschleife. 
In jedem Durchlauf wird ein Event aus der Schlange entnommen und wird einige Zeit sp\"ater an den Zielprozess weitergeleitet.
\item \textbf{Synchrone Events} gleichen einem Funktionsaufruf.
Sie werden ohne Umweg \"uber die Warteschlange direkt an den Empf\"anger-Prozess
zugestellt \cite[vgl.][S. 7]{Walter:2010}.  Mit der Funktion process\_post\_synch(\&example\_process, EVENT\_ID, msg) wird gezielt ein 
Prozess aufgerufen (ein Broadcast ist nicht m\"oglich). W\"ahrend der aufgerufene Prozess aktiv ist, blockiert der Aufrufer und 
setzt seine Ausführung erst fort, wenn der aufgerufene Prozess die Kontrolle wieder abgibt.
\end{itemize}

\paragraph{Scheduling und Timer}\mbox{}\\

\paragraph{Der Rime Kommunikationsstack}\mbox{}\\
\label{sec:rime}
\input{src/flow/4_2_Treiber}
\input{src/flow/4_3_AgentRTE}
\input{src/flow/4_4_Agenten}
